{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from jax import jit\n",
    "\n",
    "import klsurprise as kls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a mock case for debuging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fiducial parameters 1 =  [0.4 0.1]\n",
      "Fiducial parameters 2 =  [1.3 0.2]\n"
     ]
    }
   ],
   "source": [
    "# Set the seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Constants and dimensions\n",
    "theta_dim = 2\n",
    "D_dim = 7\n",
    "\n",
    "# Gera um vetor de parametros \\theta_1 e theta_2\n",
    "theta_fid_1 = np.array([0.4, 0.1])\n",
    "theta_fid_2 = np.array([1.3, 0.2])\n",
    "\n",
    "\n",
    "# generate F(theta) related quantities\n",
    "F0 = np.random.rand(D_dim)  # 7x1 vector\n",
    "M = np.random.rand(D_dim, theta_dim)  # 7x2 matrix\n",
    "# generate covariance matrix for likelihood L2\n",
    "C = np.random.rand(D_dim, D_dim)  # 7x7 matrix\n",
    "# generate covariance matrix for posterior 1\n",
    "Sigma_1 = np.random.rand(theta_dim, theta_dim)  # 2x2 matrix\n",
    "\n",
    "# Ensure C and Sigma are symmetric and positive-definite\n",
    "C = np.dot(C, C.T)\n",
    "Sigma_1 = np.dot(Sigma_1, Sigma_1.T)\n",
    "invS1 = np.linalg.inv(Sigma_1)\n",
    "\n",
    "# covariance matrix of posterior 2\n",
    "# Assuming Gaussianity and a flat prior, we can also derive the equations for Sigma_2. \n",
    "# See https://arxiv.org/abs/1402.3593 eq. A17.\n",
    "invC  = np.linalg.inv(C)\n",
    "invS2 = np.dot(M.T, np.dot(invC, M))\n",
    "Sigma_2 = np.linalg.inv(invS2)\n",
    "\n",
    "# Define the linear function F(theta)\n",
    "def F(theta):\n",
    "    return F0 + np.dot(M, theta)\n",
    "\n",
    "# fiducial data vectors\n",
    "################# hey there, maybe you should think some more here about putting noise to this vector!\n",
    "D1_fid = F(theta_fid_1) \n",
    "D2_fid = F(theta_fid_2)\n",
    "\n",
    "print(\"Fiducial parameters 1 = \", theta_fid_1)\n",
    "print(\"Fiducial parameters 2 = \", theta_fid_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_gaussian_pdf(theta, mean, cov):\n",
    "    \"\"\"\n",
    "    Calculate the PDF of a multivariate Gaussian distribution.\n",
    "\n",
    "    Parameters:\n",
    "    mean : array-like, shape (n,)\n",
    "        The mean vector of the Gaussian distribution.\n",
    "    cov : array-like, shape (n, n)\n",
    "        The covariance matrix of the Gaussian distribution.\n",
    "    theta : array-like, shape (n,)\n",
    "        The parameter vector at which to evaluate the PDF.\n",
    "\n",
    "    Returns:\n",
    "    pdf_value : float\n",
    "        The PDF value of the multivariate Gaussian at the data point.\n",
    "    \"\"\"\n",
    "    k = mean.shape[0]\n",
    "    diff = theta - mean\n",
    "    inv_cov = jnp.linalg.inv(cov)\n",
    "    logL = -0.5 * jnp.dot(diff, jnp.dot(inv_cov, diff))\n",
    "    norm_factor = jnp.log(jnp.sqrt((2 * jnp.pi) ** k * jnp.linalg.det(cov)))\n",
    "    logpdf_value = logL - norm_factor\n",
    "    return logpdf_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define both loglikelihoods that will be used in the main function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the distributions as callable functions of theta and D\n",
    "@jit\n",
    "def logL1(theta):\n",
    "    return multivariate_gaussian_pdf(theta, theta_fid_1, Sigma_1)\n",
    "    \n",
    "def logL2(theta, D2):\n",
    "    return multivariate_gaussian_pdf(theta, theta_fid_2, Sigma_2)\n",
    "\n",
    "domain = np.array([[5,-5], [5,-5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debuging part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3121698894.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    sup = kls.surprise_statistics(logL1, F, covariance_matrix_2=)\u001b[0m\n\u001b[0m                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "sup = kls.surprise_statistics(logL1, F, covariance_matrix_2=Sigma_1, domain=domain, data_2=D2_fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (surprise)",
   "language": "python",
   "name": "surprise"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
